

Spark Core
+ Local
+ Yarn
+ RDD

Spark SQL
+ Dataset
+ SQL
+ UDF
+ UDAF

Spark Streaming
+ Socket
+ Kafka

分布式计算的核心是切分数据，减小数据规模

spark 基于 mr 开发

spark、kafka一部分、flink是 scala开发的


spark对比mr:
1、开发语言
mr是java开发的不适合进行大量的数据处理
spark是scala开发的适合大量数据的处理

2、处理方式
mp： file->mapper->reader->file
之考虑单一计算

多逻辑要多次计算

file->mapper->reader->file->mapper->reader->file->mapper->reader->file

会有大量的磁盘读写

spark 会把中间的file存在内存里

 ---

 Spark 是一种基于内存的快速、通用、可扩展的大数据分析计算引擎。


 mp早期设计之考虑一次性计算，每次计算结果都落盘

 spark框架计算比MR快的原因：中间结果不落盘。注意Spark的Shuffle也是落盘的。


资源管理：
Yarn+Spark
Spark+Spark

 # 部署
 + Local模式：在本地部署单个Spark服务
 + Standalone模式：Spark自带的任务调度模式。
 + Yarn模式：Spark用Hadoop的Yarn组键进行资源与任务调度。（常用）
 + Mesos模式：Spark使用Mesos平台进行资源与任务的调度。

 https://spark.apache.org/downloads.html 
 下载

 # Local 模式运行
 bin/spark-submit \
 --class org.apache.spark.examples.SparkPi \
 --master local[10] \  多线程10个 
 ./examples/jars/spark-examples_2.12-3.5.1.jar \
 10


# yarn
https://www.bilibili.com/video/BV12142167BL?p=13&vd_source=75b5a4665a5280dc40c714fc1ad5c04b


/usr/local/spark/conf/spark-env.sh

+ YARN_CONF_DIR=/usr/local/hadoop/etc/hadoop


yarn 模式
resourceManager

yarn-client：Driver程序运行在客户端，适用于交互、调试、希望立即看到app输出
yarn-cluster：Driver程序运行在由ResourceManager启动的AppMaster，适用于生产环境


 bin/spark-submit \
 --class org.apache.spark.examples.SparkPi \
 --master yarn \
 --deploy-mode cluster \ 
 ./examples/jars/spark-examples_2.12-3.5.1.jar \
 10

 # standalone
 计算用spark，资源也用spark