[TOC]

相关性算分是指文档与查询语句间的相关度，英文为relevance
通过倒排索引可以获取与查询语句相匹配的文档列表，那么如何将最符合用户查询的文档放到前列呢？
本质是一个排序问题，排序的依据是相关性算分


在es中，有query和filter两种不同的context
+ query contex：相关性算分
+ filter context：不需要算分（yes or no），可以利用cache，获得更好的性能


# 相关性算分的几个重要概念
+ Term Frequency(TF)词频，即单词在一篇文档中出现的次数。词频越高，相关度越高（检索词出现的次数除以文档的总字数）
+ Document Frequency(DF)文档频率，即单词在所有的的文档中出现的次数
+ Inverse Document Frequency(IDF)逆向文档频率，简单说=log(全部文档数/检索词出现的文档总数)
+ Field-length Norm文档越短，相关性越高

检索”区块链的应用“分词为”区块链“，”的“，”应用“
SCORE=TF(区块链)*IDF(区块链)+TF(的)*IDF(的)+TF(应用)*IDF(应用)

|       | 出现的文档数 | 总文档数 |      IDF      |
| ----- | ---------- | ------ | ------------ |
| 区块链 | 200w       | 10e     | log(500)=8.96 |
| 的    | 10e        | 10e     | log(1)=0      |
| 应用   | 5e         | 10e     | log(2)=1      |

# ES目前主要有两个相关性算分模型
+ TF/IDF模型
+ BM25模型，5.x之后默认的模型

![](https://gitee.com/caijingquan/imagebed/raw/master/1602320874_20200315215236205_464901665.png)

可以通过explain参数来查看具体的计算方法，但要注意：
+ es的算分是按照shard进行的，即shard的分数计算是相互独立的，所以在使用explain的时候注意分片数
+ 可以通过设置索引的分片数为来避免这个问题

![](https://gitee.com/caijingquan/imagebed/raw/master/1602320876_20200315221842527_1876310560.png)

![](https://gitee.com/caijingquan/imagebed/raw/master/1602320877_20200315221914983_1246248671.png)


# 概览
TF-IDF（term frequency–inverse document frequency）是一种用于信息检索与数据挖掘的常用加权技术
+ TF：词频，这个document文档包含了多少个这个词，包含越多表明越相关
+ DF：文档频率，包含改词的文档总数目
+ IDF：DF取反

| 单词id |   单词   | 文档频率 |            倒排列表（DocID;TF;\<POS>）            |
| ----- | -------- | ------ | ---------------------------------------------- |
| 1     | google   | 5       | (1;1;\<1>) ,(2;1;\<1>) ,(3;1;\<1;6>) ,(4;1;\<1>) |
| 2     | facebook | 3       | (1;1;\<2>) ,(4;1;\<1>)                          |
| 3     | linux    | 1       | (2;1;\<10>)                                      |

TF-IDF打分：
google这个词一共出现了5次，df=5，idf=1/5，在文档3中出现了2次，所以它的if-idf=2/5

es还有归一化加权

# TF(term frequency)
词频，指的是某一个给定的词语在该文件（注意这里的该文件与后面所有文本的区别）中出现的次数，这个数字通常会被归一化(一般是词频除以文章总词数), 以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）

# IDF(inverse Document frequency)
逆文本频率指数，反应了一个词在所有文本（整个文档）中出现的频率，如果一个词在很多的文本中出现，那么它的IDF值应该低。而反过来如果一个词在比较少的文本中出现，那么它的IDF值应该高。比如一些专业的名词如“Machine Learning”。这样的词IDF值应该高。一个极端的情况，如果一个词在所有的文本中都出现，那么它的IDF值应该为0

# 为什么要用TF-IDF
因为计算机只能识别数字，对于一个一个的单词，计算机是看不懂的，更别说是一句话，或是一篇文章，而TF-IDF就是用来将文本转换成计算机看得懂的语言，或者说是机器学习或深度学习模型能够进行学习训练的数据集

# BM25