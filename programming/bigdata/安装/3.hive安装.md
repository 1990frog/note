[[TOC]]

# 编辑hive-env.sh
```
export HADOOP_HOME=/usr/local/hadoop
export HIVE_CONF_DIR=/usr/local/hive/conf
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk
```

# 编辑hive-site.xml
配置mysql数据库的jdbc地址、驱动、用户和密码等等
```xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration> 
	<!--mysql地址-->
	<property> 
		<name>javax.jdo.option.ConnectionURL</name>  
		<value>jdbc:mysql://localhost:3306/metastore?createDatabaseIfNotExist=true</value>  
	<description>the URL of the MySQL database</description> 
	</property>
	<!--JDBC驱动-->
	<property> 
		<name>javax.jdo.option.ConnectionDriverName</name>  
		<value>com.mysql.cj.jdbc.Driver</value>  
	<description>Driver class name for a JDBC metastore</description> 
	</property>
	<!--用户名-->
	<property> 
		<name>javax.jdo.option.ConnectionUserName</name>  
		<value>root</value> 
	</property>
	<!--密码-->
	<property> 
		<name>javax.jdo.option.ConnectionPassword</name>  
		<value>root</value> 
	</property>
	<!---->
	<property> 
		<name>hive.metastore.warehouse.dir</name>  
		<value>/hive/warehouse</value> 
	</property>
	<!---->
	<property> 
		<name>hive.exec.scratchdir</name>  
		<value>/hive/tmp</value> 
	</property>
	<!---->
	<property> 
		<name>hive.querylog.location</name>  
		<value>/hive/log</value> 
	</property>
	<!---->
	<property> 
		<name>hive.metastore.schema.verification</name>  
		<value>false</value> 
	</property>
	<!---->
	<property> 
		<name>datanucleus.autoCreateSchema</name> 
		<value>true</value> 
	</property> 
	<!---->
	<property> 
		<name>datanucleus.autoCreateTables</name> 
		<value>true</value> 
	</property>
</configuration>
```

# mysql驱动
```
sudo cp /$MAVEN_HOME/mysql/mysql-connector-java/8.0.20/mysql-connector-java-8.0.20.jar $HIVE_HOME/lib/
```

# hdfs创建文件
```
> hdfs dfs -mkdir /hive
> hdfs dfs -mkdir /hive/warehouse
> hdfs dfs -mkdir /hive/log
> hdfs dfs -mkdir /hive/tmp
> hdfs dfs -chmod -R 777 /hive
```

# hive初始化
```
> schematool -initSchema -dbType mysql
> schematool -dbTpe mysql -initSchema
```

# hive启动
```
> hive --service metastore &
hive --service hiveserver2 &
```

还配置了Hive在HDFS上的一些相关的目录
接下来我们需要在HDFS上创建相关的目录


# 错误收集
```
> schematool -initSchema -dbType mysql
Exception in thread "main" java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338)
        at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:536)
        at org.apache.hadoop.mapred.JobConf.setJarByClass(JobConf.java:554)
        at org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:448)
        at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:4045)
        at org.apache.hadoop.hive.conf.HiveConf.<init>(HiveConf.java:4008)
        at org.apache.hive.beeline.HiveSchemaTool.<init>(HiveSchemaTool.java:82)
        at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1117)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
```
com.google.common.base.Preconditions.checkArgument 这是因为hive内依赖的guava.jar和hadoop内的版本不一致造成的。

hive中guava.jar位置/hive/lib/
hadoop中guava.jar位置/hadoop/share/hadoop/common/lib/


版本选择
hadoop3.3+hive3.1