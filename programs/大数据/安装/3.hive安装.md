[[TOC]]

# 编辑hive-env.sh
```
export HADOOP_HOME=/usr/local/hadoop/3.2.1
export HIVE_CONF_DIR=/usr/local/hive/conf
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk
```

# 编辑hive-site.xml
配置mysql数据库的jdbc地址、驱动、用户和密码等等
```xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration> 
	<!--mysql地址-->
	<property> 
		<name>javax.jdo.option.ConnectionURL</name>  
		<value>jdbc:mysql://localhost:3306/metastore?createDatabaseIfNotExist=true</value>  
	<description>the URL of the MySQL database</description> 
	</property>
	<!--JDBC驱动-->
	<property> 
		<name>javax.jdo.option.ConnectionDriverName</name>  
		<value>com.mysql.jdbc.Driver</value>  
	<description>Driver class name for a JDBC metastore</description> 
	</property>
	<!--用户名-->
	<property> 
		<name>javax.jdo.option.ConnectionUserName</name>  
		<value>root</value> 
	</property>
	<!--密码-->
	<property> 
		<name>javax.jdo.option.ConnectionPassword</name>  
		<value>root</value> 
	</property>
	<!---->
	<property> 
		<name>hive.metastore.warehouse.dir</name>  
		<value>/hive/warehouse</value> 
	</property>
	<!---->
	<property> 
		<name>hive.exec.scratchdir</name>  
		<value>/hive/tmp</value> 
	</property>
	<!---->
	<property> 
		<name>hive.querylog.location</name>  
		<value>/hive/log</value> 
	</property>
	<!---->
	<property> 
		<name>hive.metastore.schema.verification</name>  
		<value>false</value> 
	</property>
	<!---->
	<property> 
		<name>datanucleus.autoCreateSchema</name> 
		<value>true</value> 
	</property> 
	<!---->
	<property> 
		<name>datanucleus.autoCreateTables</name> 
		<value>true</value> 
	</property>
</configuration>
```

# mysql驱动
```
sudo cp /$MAVEN_HOME/mysql/mysql-connector-java/8.0.20/mysql-connector-java-8.0.20.jar $HIVE_HOME/lib/
```

# hdfs创建文件
```
> hdfs dfs -mkdir /hive
> hdfs dfs -mkdir /hive/warehouse
> hdfs dfs -mkdir /hive/log
> hdfs dfs -mkdir /hive/tmp
> hdfs dfs -chmod -R 777 /hive
```

# hive初始化
```
> schematool -initSchema -dbType mysql
> schematool --dbTpe mysql --initSchema
```

# hive启动
```
> hive --service metastore &
> hive --service hiveserver2 &
```

还配置了Hive在HDFS上的一些相关的目录
接下来我们需要在HDFS上创建相关的目录