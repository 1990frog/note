[[TOC]]

# 环境变量
```
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk
export JRE_HOME=${JAVA_HOME}/jre
export PATH=${JAVA_HOME}/bin:$PATH
export HADOOP_HOME=/usr/local/hadoop
export PATH=${HADOOP_HOME}/bin:/sbin:$PATH
```

# 版本选择
+ CDH
+ apache

# 解压hadoop
...

# 编辑配置文件
hadoop/etc/hadoop

## 编辑hadoop-env.sh
添加JAVA_HOME
export JAVA_HOME = /usr/lib/jvm/java-8-openjdk

## 编辑core-site.xml
namenode
```xml
<configuration>
    <!-- 指定namenode地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://0.0.0.0:9000</value>
    </property>
    <!-- 用来指定使用hadoop时产生文件的存放目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/home/cai/App/hadoop/tmp/name</value>
    </property>
    <!-- 配置该superUser允许通过代理访问的主机节点 -->
    <property>
        <name>hadoop.proxyuser.cai.hosts</name>
        <value>*</value>
    </property>
    <!-- 配置该superUser允许代理的用户所属组 -->
    <property>
        <name>hadoop.proxyuser.cai.groups</name>
        <value>*</value>
    </property>
    <!-- 配置该superUser允许代理的用户 -->
    <property>
        <name>hadoop.proxyuser.cai.users</name>
        <value>用户1,用户2</value>
    </property>
</configuration>
```

## 编辑hdfs-site.xml
hdfs
```xml
<configuration>
    <!--指定hdfs保存数据的副本数量-->
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <!--指定hdfs中namenode的存储位置-->
    <property>
        <name>dfs.namenode.name.dir</name> 
        <value>file:/home/cai/App/hadoop/tmp/name</value>
    </property>
    <!--指定hdfs中datanode的存储位置-->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/home/cai/App/hadoop/tmp/data</value>
    </property>
    <property>  
        <name>dfs.webhdfs.enabled</name> 
        <value>true</value>
    </property> 
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>20</value>
    </property>
</configuration>
```

## mapred-site.xml
mapreduce
```xml
<configuration>
    <!--告诉hadoop以后MR(Map/Reduce)运行在YARN上-->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```
## yarn-site.xml
yarn
```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

# hadoop格式化启动
```
> hdfs namenode -format
```
记得文件夹权限
```
> sudo chmod -R 777 /home/cai/App/hadoop/tmp
```

# 创建hadoop用户
```
useradd -m hadoop -s /bin/bash # 添加hadoop用户
passwd hadoop # 配置hadoop用户的密码，需要输入两次
visudo #打开配置文件 在最后一行加入 hadoop ALL=(ALL) ALL 并保存。  
为hadoop添加管理员权限
```

