[TOC]

# 多级缓存
+ redis缓存
+ 热点内存本地缓存
+ nginx proxy cache缓存
+ nginx lua缓存

# 三种模式
+ 单机
+ sentinal
+ cluster

# reids直接缓存对象异常
未实现序列化接口
```java
public class bean implements Serializable{
    ...
}
```
有个坑，bean内嵌bean，那要全部都实现Serializable接口

# 本地热点缓存
+ 热点数据
+ 脏读非常不敏感
+ 内存可控

如果分布式部署，要清除jvm内的数据，那就要求每个服务的jvm都被清除
（也可以用mq发送消息触发监听应用清除jvm数据，但是这样做往往是得不偿失的，既然做了本地的热点，那么这种数据变化的频率是非常低的，而且就算有变化的频率，也不需要去清除，要对脏读做到不敏感，再加上内存是要可控的，这个热点缓存的生命周期必定是不会特别长的）

# Guava cache
+ 可控制的大小和超时时间
+ 可控制的lru策略
+ 线程安全

# nginx proxy cache
+ nginx反向代理前置
+ 依靠文件系统存索引级的文件
+ 依靠内存缓存文件地址

nginx.conf
```
# 声明一个cache缓存节点的内容
proxy_cache_path /usr/local/openresty/nginx/tmp_cache levels=1:2 keys_zone=tmp_cache:100m inactive=7d max_size=10g;

```

受本地磁盘速度影响（最好nas，或顶级ssd），但是还是无法跟内存相比

# nginx lua
+ lua协程机制
+ nginx协程机制
+ nginx lua插载点
+ OpenResty

# 协程机制
+ 依附于线程的内存模型，切换开销小
+ 遇阻塞及归还执行权，代码同步
+ 协程在线程中是串行执行的，所以无需加锁

resume
yield

# nginx协程
+ nginx的每一个Worker进程都是在epoll或kqueue这种事件模型之上，封装成协程
+ 每一个请求都有一个协程进行处理
+ 即使ngx_lua需要运行lua，相对c有一定的开销，但依旧能保证并发能力

# nginx协程机制
+ nginx每个工作进程创建一个lua虚拟机
+ 工作进程内的所有协程共享同一个vm
+ 每个外部请求由一个lua协程处理，之间数据隔离
+ lua代码调用io等异步接口时，协程被挂起，上下文数据保持不变
+ 自动保存，不阻塞工作进程
+ io异步操作完成后还原协程上下文，代码继续执行

java处理http请求是一个请求对应一个线程线程处理的




`mkdir lua`
`vim init.lua`

init.lua
```
ngx.log(ngx.ERR,"init lua success");
```
使用
vim /conf/nginx.conf

# OpenResty
+ OpenResty由Nginx核心加很多第三方模块组成，默认集成了Lua开发环境，使得Nginx可以作为一个Web Server使用
+ 借助于Nginx的事件驱动模型和非阻塞IO，可以实现高性能的Web应用程序
+ OpenResty提供了大量组件如Mysql、Redis、Memcached等等，使在Nginx上开发web应用更方便更简单

# Openresty实践
+ openresty hello world
+ shared dic:共享内存字典，所有worker进程可见，lru淘汰
+ openresty redis支持

# hello world
location /helloworld{
    content_by_lua_file ../lua/helloworld.lua
}

ngx.exec("/item/get?id=6");



guava cache
openresty redis/shared dic

tomcat对redis的支持

性能最高的就是将缓存推到离用户最近的地方，代价是更占用系统分布式的资源，越往上越昂贵，更新机制更难，但是性能却越高

脏读的忍受情况，决定动态缓存的方案